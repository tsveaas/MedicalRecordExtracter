{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06d9d13",
   "metadata": {},
   "source": [
    "# Medical Record Extracter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c3552",
   "metadata": {},
   "source": [
    "## This function reads raw medical files and extracts the recordings as a list of dictionarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb9d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78cf7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition\n",
    "def parameter_dictionary(raw_text, params_df):\n",
    "    \"\"\"\n",
    "    Clean raw medical results\n",
    "    Extracts parameters, values, unit into a list of dictionarys\n",
    "    \n",
    "    Parameters:\n",
    "        raw_text(string): The raw medical data\n",
    "        params_df: Dataframe of parameter abbreviations and synonyms from json file\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries (\"parameter\", \"value\", \"unit\")\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert all string values in params df to lowercase, including strings within lists\n",
    "    params_df = pd.DataFrame({col: [item.lower() if isinstance(item, str) else [subitem.lower() for subitem in item]\n",
    "                                    for item in params_json[col]] for col in params_json.columns})\n",
    "    # Convert raw text to lower case\n",
    "    lower_text = raw_text.lower()\n",
    "    \n",
    "    # Format the params df\n",
    "    # Group the synonyms of the parameters that appear more than once.\n",
    "    params_df = params_df.groupby('Abbreviation')['Synonyms'].agg(lambda x: sum(x, [])).reset_index()\n",
    "    # Add the abbreviation to the synonyms row\n",
    "    params_df['Synonyms'] = params_df.apply(lambda row: [row['Abbreviation']] + row['Synonyms'], axis =1)\n",
    "    \n",
    "    # Clean raw text\n",
    "    # Split raw sample into list of its lines\n",
    "    sample_list = lower_text.split('\\n')\n",
    "    # Remove parenthesis and contents\n",
    "    sample_list = [re.sub(r'\\([^()]*\\)|\\[[^\\[\\]]*\\]', '', line) for line in sample_list]\n",
    "    # Remove dates from lines\n",
    "    sample_list = [re.sub(r'\\b\\d{2}/\\d{2}/\\d{2,4}\\b', '', line) for line in sample_list]\n",
    "    # Only keep lines with numbers in them\n",
    "    sample_list = [line for line in sample_list if re.search(r'\\d', line)] \n",
    "    \n",
    "    # initialise lists to be used for resulting output\n",
    "    output_list = []\n",
    "    seen_params = set()\n",
    "    \n",
    "    for line in sample_list:\n",
    "        # Initialise variables to store detected parameters in line\n",
    "        detected = []\n",
    "        abbrev_no = []\n",
    "        #iterate through each synonym in the parameter df to find any matching in the line\n",
    "        for j, synonyms in enumerate(params_df['Synonyms']):\n",
    "            for synonym in synonyms:\n",
    "                \n",
    "                # Use regex pattern to maken sure matching synonym is a complete word for strict matching\n",
    "                pattern = r'\\b' + synonym + r'\\b'\n",
    "                # Use only strict matching for shorter length synonyms\n",
    "                if len(synonym) < 5:\n",
    "                    # Check if the pattern matches the line\n",
    "                    if re.search(pattern, line):\n",
    "                        detected.append(synonym)\n",
    "                        abbrev_no.append(j)\n",
    "                \n",
    "                # Use fuzzy matching as well for longer length synonyms to account for slight recording errors\n",
    "                elif re.search(pattern, line) or fuzz.partial_ratio(synonym, line) >= 85:\n",
    "                    detected.append(synonym)\n",
    "                    abbrev_no.append(j)\n",
    "       \n",
    "        # look for values if a synonym has ben detected\n",
    "        if detected:            \n",
    "            # Select the parameter detected from the line as the abbreviation for the longest detected synonym\n",
    "            param = params_df['Abbreviation'][abbrev_no[np.argmax([len(s) for s in detected])]]\n",
    "            matching_synonym = max(detected, key = len)\n",
    "            \n",
    "            # Split line up on spaces into elements\n",
    "            elements = re.split(r'\\s+', line)\n",
    "            \n",
    "            # Find the unit by finding element that contains / or %\n",
    "            # Make sure it is the last matching element\n",
    "            unit = None\n",
    "            for element in reversed(elements):\n",
    "                if '/' in element or '%' in element:\n",
    "                    unit = element\n",
    "                    elements.remove(element)\n",
    "                    break\n",
    "            \n",
    "            # Find the unit by finding element that only contains numbers\n",
    "            # Make sure it is the last matching element\n",
    "            value = None\n",
    "            for element in reversed(elements):\n",
    "                if any(char.isdigit() for char in element):\n",
    "                    value = element\n",
    "                    break\n",
    "            \n",
    "            # Only add recording dictionary if all keys have values\n",
    "            if all([param, value, unit]):\n",
    "                # Only add the recording if the parameter hasn't been recorded already\n",
    "                if param not in seen_params:\n",
    "                    output_list.append({\n",
    "                        \"parameter\": param,\n",
    "                        \"value\": value,\n",
    "                        \"unit\": unit\n",
    "                    })\n",
    "                    seen_params.add(param)\n",
    "    \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205458a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 27s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'parameter': 'rbc', 'value': '14', 'unit': 'x10*6/l'},\n",
       " {'parameter': 'gglo', 'value': '11', 'unit': 'iu/ml'},\n",
       " {'parameter': 'na+', 'value': '140', 'unit': 'mmol/l'},\n",
       " {'parameter': 'k+', 'value': '4.5', 'unit': 'mmol/l'},\n",
       " {'parameter': 'cl-', 'value': '106', 'unit': 'mmol/l'},\n",
       " {'parameter': 'co2', 'value': '25', 'unit': 'mmol/l'},\n",
       " {'parameter': 'urea', 'value': '5.1', 'unit': 'mmol/l'},\n",
       " {'parameter': 'crea', 'value': '65', 'unit': 'umol/l'},\n",
       " {'parameter': 'egfr', 'value': '>90', 'unit': 'ml/min/1.73m2'},\n",
       " {'parameter': 'ca2+', 'value': '2.40', 'unit': 'mmol/l'},\n",
       " {'parameter': 'p5+', 'value': '1.08', 'unit': 'mmol/l'},\n",
       " {'parameter': 'biliin', 'value': '18', 'unit': 'umol/l'},\n",
       " {'parameter': 'alp', 'value': '70', 'unit': 'u/l'},\n",
       " {'parameter': 'ggt', 'value': '15', 'unit': 'u/l'},\n",
       " {'parameter': 'ast', 'value': '23', 'unit': 'u/l'},\n",
       " {'parameter': 'alt', 'value': '22', 'unit': 'u/l'},\n",
       " {'parameter': 'prot', 'value': '72', 'unit': 'g/l'},\n",
       " {'parameter': 'alb', 'value': '46', 'unit': 'g/l'},\n",
       " {'parameter': 'trigl', 'value': '0.6', 'unit': 'mmol/l'},\n",
       " {'parameter': 'gluc', 'value': '4.7', 'unit': 'mmol/l'},\n",
       " {'parameter': 'fgluc', 'value': '5.5', 'unit': 'mmol/l'},\n",
       " {'parameter': 'tfer', 'value': '2.7', 'unit': 'g/l'},\n",
       " {'parameter': 'ferr', 'value': '47', 'unit': 'ug/l'},\n",
       " {'parameter': 'chol', 'value': '2.0', 'unit': 'mmol/l'},\n",
       " {'parameter': 'vldlc', 'value': '>1.0', 'unit': 'mmol/l'},\n",
       " {'parameter': 'nonhdl', 'value': '<3.3', 'unit': 'mmol/l'},\n",
       " {'parameter': 'hba1c', 'value': '134', 'unit': 'g/l'},\n",
       " {'parameter': 'mchc', 'value': '325', 'unit': 'g/l'},\n",
       " {'parameter': 'wbc', 'value': '7.9', 'unit': 'x10*9/l'},\n",
       " {'parameter': 'neut', 'value': '4.11', 'unit': 'x10*9/l'},\n",
       " {'parameter': 'lympho%', 'value': '2.96', 'unit': 'x10*9/l'},\n",
       " {'parameter': 'mono', 'value': '0.59', 'unit': 'x10*9/l'},\n",
       " {'parameter': 'eos', 'value': '0.17', 'unit': 'x10*9/l'},\n",
       " {'parameter': 'baso', 'value': '0.04', 'unit': 'x10*9/l'},\n",
       " {'parameter': 'nrbcs', 'value': '<1.0', 'unit': '/100'},\n",
       " {'parameter': 'plat', 'value': '261', 'unit': 'x10*9/l'},\n",
       " {'parameter': 'esr', 'value': '1', 'unit': 'mm/h'},\n",
       " {'parameter': 'tsh', 'value': '2.99', 'unit': 'milu/l'},\n",
       " {'parameter': 'vitd', 'value': '83', 'unit': 'nmol/l'},\n",
       " {'parameter': 'galt', 'value': '29', 'unit': 'nmol/l'},\n",
       " {'parameter': 'pheala', 'value': '20', 'unit': 'nmol/l'},\n",
       " {'parameter': 'uric', 'value': '0.21', 'unit': 'mmol/l'},\n",
       " {'parameter': 'pth', 'value': '3.5', 'unit': 'pmol/l'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Usage Example\n",
    "\n",
    "# Load raw files\n",
    "with open('0b8706dc-c9af-4c6b-887d-2f85b5a511e7.txt', 'r', encoding='latin1') as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "params_json = pd.read_json('X1.json')\n",
    "\n",
    "# Run function and view results\n",
    "results = parameter_dictionary(raw_text, params_json)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b7c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
